{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTlZOBMhcv-n"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path to the directory above the current one\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Double-check your current directory\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print(f\"Project root added to path. You can now import.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XTiI2NT0d0FO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image, ImageOps\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "38AyrbFtQUox"
   },
   "outputs": [],
   "source": [
    "# Adjust the config values based on your preference\n",
    "config = {\"n_classes\": 21,\n",
    "          \"lr_rate\": 0.001,\n",
    "          \"batch_size\": 16,\n",
    "          \"num_workers\": 2,\n",
    "          \"resolution\": 256,\n",
    "          \"sch_step_size\": 15,\n",
    "          \"sch_gamma\": 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Taxd1tid2dW"
   },
   "outputs": [],
   "source": [
    "! pip install urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIV2nzjyd4xQ"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"gopalbhattrai/pascal-voc-2012-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybJlhYU813-Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define source (Read-only) and target (Writable wrapper)\n",
    "# Note: We need to point to the actual VOCdevkit folder inside the input\n",
    "input_root = '/kaggle/input/pascal-voc-2012-dataset'\n",
    "target_root = '/content/VOCdevkit/VOC2012'\n",
    "\n",
    "# Create the destination directory structure (but not the final folder)\n",
    "os.makedirs('/content/VOCdevkit', exist_ok=True)\n",
    "\n",
    "# Create the Symlink\n",
    "# This creates a \"ghost\" folder at target_root that points to input_root\n",
    "if not os.path.exists(target_root):\n",
    "    print(f\"Creating symlink: {target_root} -> {input_root}\")\n",
    "    os.symlink(input_root, target_root)\n",
    "    print(\"Success! (No copying required)\")\n",
    "else:\n",
    "    print(\"Symlink already exists.\")\n",
    "\n",
    "# Verify it works\n",
    "print(\"\\nVerifying structure...\")\n",
    "!ls -F /content/VOCdevkit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhCH7Fz_d9iN"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# The path you got from the download\n",
    "cached_path = '/root/.cache/kagglehub/datasets/gopalbhattrai/pascal-voc-2012-dataset/versions/1'\n",
    "target_path = '/content/VOCdevkit'\n",
    "\n",
    "# Check if we already moved it to avoid errors\n",
    "if not os.path.exists(target_path):\n",
    "    print(f\"Moving data from {cached_path} to {target_path}...\")\n",
    "    # We use move because it's instant (metadata change only)\n",
    "    shutil.move(cached_path, target_path)\n",
    "    print(\"Move complete!\")\n",
    "else:\n",
    "    print(\"Data is already in /content/VOCdevkit\")\n",
    "\n",
    "print(\"\\nDirectory Structure:\")\n",
    "!find /content/VOCdevkit -maxdepth 2 -type d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQRhYm0iN9-6"
   },
   "source": [
    "If you encounter a `FileNotFoundError`, it is likely due to a symlink failure.\n",
    "\n",
    "**Symptom**: There is only a single `VOC2012` file inside the VOCdevkit directory instead of a folder.\n",
    "\n",
    "**Solution**: Delete the created `VOCdevkit` and directory and the `VOC2012` file in it. Skip the symlink cell entirely and run the Kaggle Direct Download cell instead. Note that in this case, the data root path will not have `VOC2012` before `VOC2012_train_val` directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtvwfjE0eWj3"
   },
   "outputs": [],
   "source": [
    "# NOTE: This utility is consistent with V1 to V4 to maintain a controlled experimental environment\n",
    "from core.data_engine import VOCDataEngine # Handles data loading and DataLoader creation automatically\n",
    "\n",
    "# One call to prepare the entire data pipeline\n",
    "engine = VOCDataEngine(root_path='/content/VOCdevkit/VOC2012/VOC2012_train_val/VOC2012_train_val', batch_size=config[\"batch_size\"], num_workers=config[\"num_workers\"], resolution=config[\"resolution\"])\n",
    "# or \"/content/VOCdevkit/VOC2012_train_val/VOC2012_train_val\" if the solution against \"FileNotFoundError\" is implemented\n",
    "train_loader, val_loader = engine.get_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "v06Jq7DBea3b"
   },
   "outputs": [],
   "source": [
    "class BaseSegmentationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.history = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_iou': [], 'val_iou': []\n",
    "        }\n",
    "        self.best_iou = 0.0\n",
    "\n",
    "    def update_history(self, train_loss, val_loss, train_iou, val_iou):\n",
    "        self.history['train_loss'].append(train_loss.item())\n",
    "        self.history['val_loss'].append(val_loss.item())\n",
    "        self.history['train_iou'].append(train_iou.item())\n",
    "        self.history['val_iou'].append(val_iou.item())\n",
    "\n",
    "    def save_checkpoint(self, path, epoch, iou):\n",
    "        if iou > self.best_iou:\n",
    "            self.best_iou = iou\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': self.state_dict(),\n",
    "                'history': self.history,\n",
    "                'best_iou': self.best_iou\n",
    "            }, path)\n",
    "            print(f\"--- Best Model Saved (mIoU: {iou:.4f}) ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "U_fljgy-en0K"
   },
   "outputs": [],
   "source": [
    "class UnetDown(nn.Module):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super().__init__()\n",
    "    model = [\n",
    "        nn.BatchNorm2d(input_size),\n",
    "        nn.ELU(),\n",
    "        nn.Conv2d(input_size, output_size, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(output_size),\n",
    "        nn.ELU(),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Conv2d(output_size, output_size, kernel_size=3, stride=1, padding=1)\n",
    "    ]\n",
    "\n",
    "    self.model = nn.Sequential(*model)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.model(x)\n",
    "\n",
    "class UnetUp(nn.Module):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super().__init__()\n",
    "\n",
    "    model = [\n",
    "        nn.BatchNorm2d(input_size),\n",
    "        nn.ELU(),\n",
    "        nn.Conv2d(input_size, output_size, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(output_size),\n",
    "        nn.ELU(),\n",
    "        nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "        nn.Conv2d(output_size, output_size, kernel_size=3, stride=1, padding=1)\n",
    "    ]\n",
    "\n",
    "    self.model = nn.Sequential(*model)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.model(x)\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super().__init__()\n",
    "\n",
    "    # Parallel branches\n",
    "    self.branch1 = nn.Sequential(\n",
    "        nn.Conv2d(input_size, output_size, kernel_size=1, bias=False),\n",
    "        nn.BatchNorm2d(output_size),\n",
    "        nn.ReLU(inplace=False)\n",
    "    )\n",
    "\n",
    "    self.branch2 = nn.Sequential(\n",
    "        nn.Conv2d(input_size, output_size, kernel_size=3, padding=2, dilation=2, bias=False),\n",
    "        nn.BatchNorm2d(output_size),\n",
    "        nn.ReLU(inplace=False)\n",
    "    )\n",
    "\n",
    "    self.branch3 = nn.Sequential(\n",
    "        nn.Conv2d(input_size, output_size, kernel_size=3, padding=4, dilation=4, bias=False),\n",
    "        nn.BatchNorm2d(output_size),\n",
    "        nn.ReLU(inplace=False)\n",
    "    )\n",
    "\n",
    "    self.branch4 = nn.Sequential(\n",
    "        nn.Conv2d(input_size, output_size, kernel_size=3, padding=8, dilation=8, bias=False),\n",
    "        nn.BatchNorm2d(output_size),\n",
    "        nn.ReLU(inplace=False)\n",
    "    )\n",
    "\n",
    "    # Global Average Pooling Branch (The \"God View\")\n",
    "    self.global_avg_pool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # Squash to 1x1\n",
    "            nn.Conv2d(input_size, output_size, 1, bias=False), # Process the global context\n",
    "            nn.BatchNorm2d(output_size),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "    # Fuse Layer (Combine all views)\n",
    "    self.fuse = nn.Sequential(\n",
    "        nn.Conv2d(output_size * 5, output_size, kernel_size=1, bias=False),\n",
    "        nn.BatchNorm2d(output_size),\n",
    "        nn.ReLU(inplace=False),\n",
    "        nn.Dropout(0.5) # Prevent overfitting to specific textures\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # Get dimensions for upsampling later\n",
    "    size = x.shape[2:]\n",
    "\n",
    "    # Run all paths in parallel\n",
    "    b1 = self.branch1(x)\n",
    "    b2 = self.branch2(x)\n",
    "    b3 = self.branch3(x)\n",
    "    b4 = self.branch4(x)\n",
    "\n",
    "    # Calculate Global Average Pooling\n",
    "    gap = self.global_avg_pool(x)\n",
    "    # Upsample the 1x1 pixel back to the feature map size\n",
    "    gap = F.interpolate(gap, size=size, mode='bilinear', align_corners=False)\n",
    "\n",
    "    # Stack them like a sandwich\n",
    "    out = torch.cat([b1, b2, b3, b4, gap], dim=1)\n",
    "\n",
    "    # Mix them\n",
    "    return self.fuse(out)\n",
    "\n",
    "class ResNetUNet(BaseSegmentationModel):\n",
    "  def __init__(self, n_classes=21):\n",
    "    super().__init__()\n",
    "    # The Encoder (Pre-trained ResNet-34)\n",
    "    # Load weights trained on ImageNet\n",
    "    self.base_model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "\n",
    "    self.base_layers = list(self.base_model.children())\n",
    "\n",
    "    # Layer 0: Initial Conv + BN + ReLU + MaxPool\n",
    "    # Output shape: [Batch, 64, H/4, W/4]\n",
    "    self.layer0 = nn.Sequential(*self.base_layers[:3])\n",
    "\n",
    "    # Layer 1: First ResBlock\n",
    "    # Output shape: [Batch, 64, H/4, W/4]\n",
    "    self.layer1 = nn.Sequential(*self.base_layers[4])\n",
    "\n",
    "    # Layer 2: Second ResBlock\n",
    "    # Output shape: [Batch, 128, H/8, W/8]\n",
    "    self.layer2 = self.base_layers[5]\n",
    "\n",
    "    # Layer 3: Third ResBlock\n",
    "    # Output shape: [Batch, 256, H/16, W/16]\n",
    "    self.layer3 = self.base_layers[6]\n",
    "\n",
    "    # Layer 4: Fourth ResBlock\n",
    "    # Output shape: [Batch, 512, H/32, W/32]\n",
    "    self.layer4 = self.base_layers[7]\n",
    "\n",
    "    self.bottleneck = ASPP(input_size=512, output_size=512)\n",
    "\n",
    "    self.up1 = UnetUp(512, 256)\n",
    "    self.up2 = UnetUp(512, 128)\n",
    "    self.up3 = UnetUp(256, 64)\n",
    "    self.up4 = UnetUp(128, 64)\n",
    "\n",
    "    self.final_conv = nn.Conv2d(128, n_classes, kernel_size=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # ---- ENCODER PATH ----\n",
    "    x = self.base_layers[0](x) # Conv1\n",
    "    x = self.base_layers[1](x) # BN\n",
    "    x0 = self.base_layers[2](x) # ReLU\n",
    "\n",
    "    x0_skip = x0.clone()\n",
    "\n",
    "    x_pool = self.base_layers[3](x0) # MaxPool\n",
    "\n",
    "    x1 = self.layer1(x_pool) # ResBlock1\n",
    "    x2 = self.layer2(x1) # ResBlock 2\n",
    "    x3 = self.layer3(x2) # ResBlock 3\n",
    "    x4 = self.layer4(x3) # ResBlock 4\n",
    "\n",
    "    x_neck = self.bottleneck(x4)\n",
    "\n",
    "    # --- DECODER PATH ---\n",
    "    d1 = self.up1(x_neck)\n",
    "    d1_ = torch.cat((d1, x3), 1)\n",
    "\n",
    "    d2 = self.up2((d1_))\n",
    "    d2_ = torch.cat((d2, x2), 1)\n",
    "\n",
    "    d3 = self.up3(d2_)\n",
    "    d3_ = torch.cat((d3, x1), 1)\n",
    "\n",
    "    d4 = self.up4(d3_)\n",
    "    d4_ = torch.cat((d4, x0), 1)\n",
    "\n",
    "    out = self.final_conv(d4_)\n",
    "    out = F.interpolate(out, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Omq51VbGe4dE"
   },
   "outputs": [],
   "source": [
    "unetv4 = ResNetUNet(n_classes=config[\"n_classes\"])\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "unetv4 = unetv4.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uiyYsPbUfAVP"
   },
   "outputs": [],
   "source": [
    "from core.losses import MulticlassDiceLoss, FocalLoss2d, LossMixer\n",
    "from core.accuracy import MulticlassIOU\n",
    "\n",
    "# Define loss functions\n",
    "loss_dice = MulticlassDiceLoss()\n",
    "loss_focal = FocalLoss2d()\n",
    "loss_fn = LossMixer(loss_dice, loss_focal)\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params=unetv4.parameters(), lr=config[\"lr_rate\"]),\n",
    "])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config[\"sch_step_size\"], gamma=config[\"sch_gamma\"])\n",
    "\n",
    "def iou_fn(y_true, y_pred):\n",
    "    multiclassIOU = MulticlassIOU(num_classes=config[\"n_classes\"])\n",
    "    iou_score = multiclassIOU.forward(y_pred, y_true)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9SqnVfAt_Ae",
    "outputId": "ab156116-17a3-43f6-eb3f-e614fa3e541a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Purged. StaticMethods should be active now.\n"
     ]
    }
   ],
   "source": [
    "# UTILITY: Re-imports local modules to reflect code changes without a kernel restart.\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "import diagnostics.model_inspector\n",
    "\n",
    "# 1. Force a reload of the specific module\n",
    "importlib.reload(diagnostics.model_inspector)\n",
    "\n",
    "# 2. Re-import the classes to the global namespace\n",
    "from core.training import Training, EarlyStopping\n",
    "\n",
    "print(\"Memory Purged. StaticMethods should be active now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iB1kF3HnfE7T"
   },
   "outputs": [],
   "source": [
    "# MODEL INSPECTOR LOGIC IS DELIBERATELY SKIPPED BECAUSE OF THE INABILITY OF THE MODEL TO OVERWRITE\n",
    "# RELU INPLACE OPERATIONS OF RESNET BACKEND\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def print_train_time(start:float,\n",
    "                     end: float,\n",
    "                     device: torch.device=None):\n",
    "  \"\"\"Prints difference between start and end time.\"\"\"\n",
    "  total_time = end - start\n",
    "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "  return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iWSHj9z2fHRK"
   },
   "outputs": [],
   "source": [
    "unetv4 = ResNetUNet(n_classes=21)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "unetv4 = unetv4.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Y-Iu5kcvfLJE"
   },
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "loss_dice = MulticlassDiceLoss()\n",
    "loss_focal = FocalLoss2d()\n",
    "loss_fn = LossMixer(loss_dice, loss_focal)\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params=unetv4.parameters(), lr=config[\"lr_rate\"]),\n",
    "])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config[\"sch_step_size\"], gamma=config[\"sch_gamma\"])\n",
    "\n",
    "def iou_fn(y_true, y_pred):\n",
    "    multiclassIOU = MulticlassIOU(num_classes=config[\"n_classes\"])\n",
    "    iou_score = multiclassIOU.forward(y_pred, y_true)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbMtAfGYfNNC"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "from core.training import Training, EarlyStopping\n",
    "\n",
    "training = Training()\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopper = EarlyStopping(patience=7, min_delta=0.01)\n",
    "\n",
    "# Set epochs\n",
    "epochs = 50\n",
    "\n",
    "# Create an optimizeation and evaluation loop using train_step() and valid_step()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  input_x, label_x = next(iter(train_loader))\n",
    "  input_y, label_y = next(iter(val_loader))\n",
    "  t_loss, t_iou = T=training.train_step(model=unetv4,\n",
    "             data_loader=train_loader,\n",
    "             loss_fn=loss_fn,\n",
    "             optimizer=optimizer,\n",
    "             accuracy_fn=iou_fn,\n",
    "             device=device)\n",
    "  v_loss, v_iou = training.valid_step(model=unetv4,\n",
    "            data_loader=val_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            accuracy_fn=iou_fn,\n",
    "            device=device)\n",
    "\n",
    "  unetv4.update_history(t_loss, v_loss, t_iou, v_iou)\n",
    "\n",
    "  # 3. Check Early Stopping\n",
    "  early_stopper(v_loss)\n",
    "  if early_stopper.early_stop:\n",
    "      unetv4.save_checkpoint(\"best_unet_v4.pth\", epoch, v_iou)\n",
    "      print(f\"Early stopping at epoch {epoch}. Model is no longer improving.\")\n",
    "      break\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RSBsnMqfYvk"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('best_unet_v4.pth', weights_only=True)\n",
    "unetv4.load_state_dict(checkpoint['model_state_dict'])\n",
    "unetv4.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qf97Ly4DRqaX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_evolution_gallery(data, target, predictions, titles, save_dir=\"inference_results\", filename=\"sample_1.png\", num_classes=21):\n",
    "    \"\"\"\n",
    "    Creates the directory and saves the side-by-side evolution plot.\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"Created directory: {save_dir}\")\n",
    "\n",
    "    num_plots = 2 + len(predictions)\n",
    "    fig, axes = plt.subplots(1, num_plots, figsize=(5 * num_plots, 5))\n",
    "    cmap = plt.get_cmap('tab20', num_classes)\n",
    "\n",
    "    # Original Image (Squeezing and permuting for [H, W, C])\n",
    "    img = data[0].permute(1, 2, 0).cpu().numpy()\n",
    "    # If normalized, denormalize here (e.g., img * std + mean)\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "\n",
    "    # Ground Truth\n",
    "    axes[1].imshow(target[0].cpu(), cmap=cmap, vmin=0, vmax=num_classes-1)\n",
    "    axes[1].set_title(\"Ground Truth\")\n",
    "\n",
    "    # Model Predictions\n",
    "    for i, pred in enumerate(predictions):\n",
    "        # Handle if pred is raw logits (B, C, H, W) or already argmaxed (B, H, W)\n",
    "        if pred.ndim == 4:\n",
    "            mask = pred[0].argmax(0).cpu().numpy()\n",
    "        else:\n",
    "            mask = pred[0].cpu().numpy()\n",
    "\n",
    "        axes[i+2].imshow(mask, cmap=cmap, vmin=0, vmax=num_classes-1)\n",
    "        axes[i+2].set_title(titles[i])\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9nP2lnGffdV6"
   },
   "outputs": [],
   "source": [
    "valid_iter = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5YWpCNbff2q"
   },
   "outputs": [],
   "source": [
    "# Get one batch from validation\n",
    "data, target = next(valid_iter)\n",
    "unetv4.eval()\n",
    "output = unetv4(data.to(device))\n",
    "pred = output.argmax(dim=1) # Convert probabilities to class labels\n",
    "\n",
    "n_images = 50\n",
    "\n",
    "for n in range(n_images):\n",
    "  save_evolution_gallery(data, target, [pred], [\"UnetV4\"], save_dir=\"unetv4_predictions\", filename=f\"unetv4_pred_{n}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3863cMYa6Tll"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
